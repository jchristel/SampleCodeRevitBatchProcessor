{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "duhast_path = r\"C:\\Users\\janchristel\\Documents\\GitHub\\SampleCodeRevitBatchProcessor\\src\"\n",
    "sys.path += [duhast_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'duHast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mduHast\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mRevit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mViews\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mReporting\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mviews_data_report\u001b[39;00m \u001b[39mimport\u001b[39;00m read_view_data_from_file\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mduHast\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mUtilities\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfiles_get\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     get_files_single_directory,\n\u001b[1;32m      4\u001b[0m     get_file_name_without_ext,\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mduHast\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mRevit\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mViews\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mReporting\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mviews_data_hash_report\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     _get_hash_headers,\n\u001b[1;32m      8\u001b[0m     _get_hash_rows_categories,\n\u001b[1;32m      9\u001b[0m     _get_hash_for_category_overrides,\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'duHast'"
     ]
    }
   ],
   "source": [
    "from duHast.Revit.Views.Reporting.views_data_report import read_view_data_from_file\n",
    "from duHast.Utilities.files_get import (\n",
    "    get_files_single_directory,\n",
    "    get_file_name_without_ext,\n",
    ")\n",
    "from duHast.Revit.Views.Reporting.views_data_hash_report import (\n",
    "    _get_hash_headers,\n",
    "    _get_hash_rows_categories,\n",
    "    _get_hash_for_category_overrides,\n",
    ")\n",
    "from duHast.Revit.Views.Reporting.view_reports_json_props import PROP_FILE_NAME\n",
    "\n",
    "JSON_DIRECTORY = r\"C:\\Users\\janchristel\\Documents\\GitHub\\SampleCodeRevitBatchProcessor\\test\\Data\\Jupyter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_FILES = get_files_single_directory(\n",
    "    folder_path=JSON_DIRECTORY, file_prefix=\"\", file_suffix=\"\", file_extension=\".csv\"\n",
    ")\n",
    "print(JSON_FILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_data(files):\n",
    "    json_data = {}\n",
    "    for file_path in files:\n",
    "        file_name = get_file_name_without_ext(file_path=file_path)\n",
    "        json_single_data = read_view_data_from_file(file_path=file_path)\n",
    "        json_data[file_name] = json_single_data\n",
    "    return json_data\n",
    "\n",
    "\n",
    "JSON_DATA_LOADED = load_json_data(JSON_FILES)\n",
    "\n",
    "print(\"found {} files\".format(len(JSON_DATA_LOADED)))\n",
    "print(type(JSON_DATA_LOADED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a storage class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class json_three_d_storage():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.column_headers = []\n",
    "        self.row_headers = []\n",
    "        self.hash_table = []\n",
    "        self.padded_default_hash_table = []\n",
    "        self.merged_column_headers=[]\n",
    "        self.merged_row_headers = []\n",
    "        self.column_indices = []\n",
    "        self.row_indices=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get hash tables per file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash_tables_by_file(view_settings):\n",
    "    dic_tables_by_file = {}\n",
    "    for key, vt_setting in view_settings.items():\n",
    "        column_headers = _get_hash_headers(vt_setting)\n",
    "        row_headers = _get_hash_rows_categories(vt_setting)\n",
    "        hash_table = _get_hash_for_category_overrides(\n",
    "            headers=column_headers, row_headers=row_headers, views_settings=vt_setting\n",
    "        )\n",
    "        storage = json_three_d_storage()\n",
    "        storage.column_headers=column_headers\n",
    "        storage.row_headers=row_headers\n",
    "        storage.hash_table=hash_table\n",
    "        dic_tables_by_file[key] = storage\n",
    "\n",
    "    return dic_tables_by_file\n",
    "\n",
    "\n",
    "HASH_DATA_BY_FILE = get_hash_tables_by_file(JSON_DATA_LOADED)\n",
    "print(HASH_DATA_BY_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build overall headers and rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_headers(view_settings, index):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        view_settings (_type_): _description_\n",
    "        index (_type_): 0 is column header, 1 is row header\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    overall_headers = []\n",
    "    for key, vt_setting in view_settings.items():\n",
    "        overall_headers = sorted(list(set(overall_headers) | set(vt_setting[index])))\n",
    "    return overall_headers\n",
    "\n",
    "\n",
    "MERGED_COLUMN_HEADERS = combine_headers(view_settings=HASH_DATA_BY_FILE, index=0)\n",
    "print(\n",
    "    \"\\n number of column headers: {}\".format(len(MERGED_COLUMN_HEADERS)),\n",
    "    MERGED_COLUMN_HEADERS,\n",
    ")\n",
    "\n",
    "MERGED_ROW_HEADERS = combine_headers(view_settings=HASH_DATA_BY_FILE, index=1)\n",
    "print(\n",
    "    \"\\n number of row headers: {}\".format(len(MERGED_ROW_HEADERS)), MERGED_ROW_HEADERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build hash tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_default_array(\n",
    "    merged_row_headers,\n",
    "    merged_column_headers,\n",
    "):\n",
    "    # Create a new padded 2D array\n",
    "    padded_array = [\n",
    "        [-1 for entry in merged_column_headers] for entry in merged_row_headers\n",
    "    ]\n",
    "    return padded_array\n",
    "\n",
    "\n",
    "for key, hash_by_file in HASH_DATA_BY_FILE.items():\n",
    "    padded_array = get_padded_default_array(\n",
    "        merged_column_headers=hash_by_file[0], merged_row_headers=hash_by_file[1]\n",
    "    )\n",
    "    HASH_DATA_BY_FILE[key].padded_default_hash_table= padded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, hash_by_file in HASH_DATA_BY_FILE:\n",
    "    # Find the indices for row and column headers in the merged headers\n",
    "    ROW_INDICES_A = [MERGED_ROW_HEADERS.index(row) for row in hash_by_file[1]]\n",
    "    COLUMN_INDICES_A = [MERGED_COLUMN_HEADERS.index(col) for col in hash_by_file[0]]\n",
    "    \n",
    "    HASH_DATA_BY_FILE[key].row_indices=ROW_INDICES_A\n",
    "    HASH_DATA_BY_FILE[key].column_indices=COLUMN_INDICES_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_default_array_values(row_indices, col_indices, default_array, value_array):\n",
    "    # Fill in the values from array_model_a\n",
    "    for i, row_index in enumerate(row_indices):\n",
    "        for j, col_index in enumerate(col_indices):\n",
    "            default_array[row_index][col_index] = value_array[i][j]\n",
    "    return default_array\n",
    "\n",
    "for key, hash_by_file in HASH_DATA_BY_FILE.items():\n",
    "    updated_array = update_default_array_values(row_indices=hash_by_file[], col_indices=hash_by_file[], default_array=hash_by_file[], value_array=hash_by_file[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
